import torch
import torch.nn as nn

__all__ = ['FilterResponseNorm1d', 'FilterResponseNorm2d',
		   'FilterResponseNorm3d']


class FilterResponseNormNd(nn.Module):

	def __init__(self, ndim, num_features, eps=1e-6,
				 learnable_eps=False):
		"""
		Input Variables:
		----------------
			ndim: An integer indicating the number of dimensions of the expected input tensor.
			num_features: An integer indicating the number of input feature dimensions.
			eps: A scalar constant or learnable variable.
			learnable_eps: A bool value indicating whether the eps is learnable.
		"""
		assert ndim in [3, 4, 5], \
			'FilterResponseNorm only supports 3d, 4d or 5d inputs.'
		super(FilterResponseNormNd, self).__init__()
		shape = (1, num_features) + (1,) * (ndim - 2)
		self.eps = nn.Parameter(torch.ones(*shape) * eps)
		if not learnable_eps:
			self.eps.requires_grad_(False)
		self.gamma = nn.Parameter(torch.Tensor(*shape))
		self.beta = nn.Parameter(torch.Tensor(*shape))
		self.tau = nn.Parameter(torch.Tensor(*shape))
		self.reset_parameters()

	def forward(self, x):
		avg_dims = tuple(range(2, x.dim()))
		nu2 = torch.pow(x, 2).mean(dim=avg_dims, keepdim=True)
		x = x * torch.rsqrt(nu2 + torch.abs(self.eps))
		return torch.max(self.gamma * x + self.beta, self.tau)

	def reset_parameters(self):
		nn.init.ones_(self.gamma)
		nn.init.zeros_(self.beta)
		nn.init.zeros_(self.tau)


class FilterResponseNorm1d(FilterResponseNormNd):

	def __init__(self, num_features, eps=1e-6, learnable_eps=False):
		super(FilterResponseNorm1d, self).__init__(
			3, num_features, eps=eps, learnable_eps=learnable_eps)


class FilterResponseNorm2d(FilterResponseNormNd):

	def __init__(self, num_features, eps=1e-6, learnable_eps=True):
		super(FilterResponseNorm2d, self).__init__(
			4, num_features, eps=eps, learnable_eps=learnable_eps)


class FilterResponseNorm3d(FilterResponseNormNd):

	def __init__(self, num_features, eps=1e-6, learnable_eps=False):
		super(FilterResponseNorm3d, self).__init__(
			5, num_features, eps=eps, learnable_eps=learnable_eps)